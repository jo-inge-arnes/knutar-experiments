```{r}
library(cladina)
library(dplyr)

```

```{r}

f_noise <- function(xs) {
  return(rnorm(length(xs), 0, 0.1))
}

f_x_dist  <- function(n) {
  return(rlnorm(n, meanlog = 0.3, sdlog = 0.4))
}


# Yield-Loss

f_signal_yield_loss <- function(x) {
  return(x / (0.5 + x))
}

generate_yield_loss <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_yield_loss, f_noise)
  return(d)
}


# Trigonometric

f_signal_trigonometric <- function(x) {
  return(cos(pi * x))
}

generate_trigonometric <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_trigonometric, f_noise)
  return(d)
}


# Logistic

f_signal_logistic <- function(x) {
  return(1 / (1 + exp(-(x - 1.5) / 0.2)))
}

generate_logistic <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_logistic, f_noise)
}


# Runge

f_signal_runge <- function(x) {
  return(1 / (1 + (x - 2)^2))
}

generate_runge <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_runge, f_noise)
}


# Michaelis Menten

f_signal_michaelis_menten <- function(x) {
  return((x * 10) / (x + 2))
}

generate_michaelis_menten <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_michaelis_menten, f_noise)
  return(d)
}


# More ...

f_signal_parabola <- function(x) {
  return(-x^2 + x*4)
}

generate_para <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_parabola, f_noise)
}


f_signal_gompertz <- function(x) {
  return(0.25 + 0.5 * exp(-exp(-2 * (x - 1.5)))) 
}

generate_gompertz <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_gompertz, f_noise)
}

f_signal_logarithmic <- function(x) {
  return(-log((x + 1) / 10))
}

generate_logarithmic <- function(n) {
  d <- generate_data(n, 2, 2, f_x_dist, f_signal_logarithmic, f_noise)
}

```

```{r}

compute_mse <- function(actual, predicted, num_knots) {
  n <- length(predicted)
  sse <- sum((actual - predicted)**2)
  return(sse / n)
}

single_sample_experiment <- function(i, n, gen_fn, max_knots) {
  # Generate data
  d <- gen_fn$fn(n)

  # Create x and y for later computing MSEs for evenly spaced values along independent axis
  # First, create 500 evenly spaced values between lower and upper independent value
  x <- data.frame(Independent = seq(from = min(d$Independent), to = max(d$Independent), length.out = 500))
  # Next, compute the true (population mean) curve values for the values in x
  y <- unlist(lapply(x$Independent, gen_fn$curve_fn))  
    
  # Get the best model given that knots are placed at quantiles within a maximum number knots
  suggested <- suggest_knotcount(d, Dependent, Independent, max_knots, stats::BIC)
  nknots_a0 <-suggested$nknots
  mod_a0 <- model_by_count(d, Dependent, Independent, nknots_a0)
  bic_a0 <- stats::BIC(mod_a0)
  mse_a0 <- compute_mse(d$SignalMeasured, mod_a0$fitted.values)
  # Predict by using mod_a0 and evenly spaced values along independent variable
  # and compute MSE
  y_hat_a0 <- predict(mod_a0, newdata = x)
  mse_a0_uniform_x <- compute_mse(y, y_hat_a0)

  # Get the best model given our approach within a maximum number knots
  res_a1 <- choose_splines(d, Dependent, Independent, max_nknots = max_knots, icr_fn = stats::BIC) 
  nknots_a1 <- length(res_a1$knots$knots)
  mod_a1 <- res_a1$model
  bic_a1 <- res_a1$score
  mse_a1 <- compute_mse(d$SignalMeasured, mod_a1$fitted.values)
  # Predict by using mod_a1 and evenly spaced values along independent variable
  # and compute MSE
  y_hat_a1 <- predict(mod_a1, newdata = x)
  mse_a1_uniform_x <- compute_mse(y, y_hat_a1)
  
  # Return a result row
  res <- list(
    "n" = n,
    "gen_fn" = gen_fn$name,
    "bic_a0" = bic_a0, "nknots_a0" = nknots_a0, "mse_a0" = mse_a0, "mse_a0_uniform_x" = mse_a0_uniform_x,
    "bic_a1" = bic_a1, "nknots_a1" = nknots_a1, "mse_a1" = mse_a1, "mse_a1_uniform_x" = mse_a1_uniform_x, 
    "bic_diff" = bic_a0 - bic_a1, "mse_diff" = mse_a0 - mse_a1, "mse_diff_uniform_x" = mse_a0_uniform_x - mse_a1_uniform_x, "nknots_diff" = nknots_a0 - nknots_a1)  
  
  R.utils::printf(".")
  
  return(res)
}

multiple_sample_experiments <- function(n, gen_fn, rep_cnt, max_knots) {
  res_list <- lapply(1:rep_cnt, single_sample_experiment, gen_fn = gen_fn, n = n, max_knots = max_knots)
  res_df <- as.data.frame(data.table::rbindlist(res_list))
  return(res_df)
}

generator_sample_experiments <- function(gen_fn, sample_sizes, samples_per_set, max_knots) {
  # Run experiments with same generator, different n, sets of many samples per n
  res_df_list <- lapply(sample_sizes, multiple_sample_experiments, gen_fn = gen_fn, rep_cnt = samples_per_set, max_knots = max_knots)
  
  res_df <- bind_rows(res_df_list, .id = "generator_sample_index")
  
  return(res_df)
}
```

```{r}
seed <- 1
set.seed(seed)

max_knots <- 4
sample_sizes <- c(100, 200, 300)
samples_per_set <- 400

# List of functions for for generating samples for different curves
generators <- list(
  list("name"= "Yield-Loss", "fn" = generate_yield_loss, "curve_fn" = f_signal_yield_loss), 
  list("name" = "Logistic", "fn" = generate_logistic, "curve_fn" = f_signal_logistic),
  list("name" = "Michaelis-Menten", "fn" = generate_michaelis_menten, "curve_fn" = f_signal_michaelis_menten),
  list("name" = "Runge", "fn" = generate_runge, "curve_fn" = f_signal_runge),
  list("name" = "Trigonometric", "fn" = generate_trigonometric, "curve_fn" = f_signal_trigonometric)
  )

res_df_list <- lapply(generators, generator_sample_experiments, sample_sizes = sample_sizes, samples_per_set = samples_per_set, max_knots = max_knots)

df_all_results <- bind_rows(res_df_list, .id = "generator_index")

experiment_finished_time <- Sys.time()

print('Completed')
```

```{r, save-result-files}
# Save results
file_name <- paste("experiment-results-", experiment_finished_time, sep = "")
file_name <- gsub("[ :]", "-", file_name)
saveRDS(df_all_results, file = paste(file_name, ".Rds", sep = ""))
write.csv(df_all_results, paste(file_name, ".csv", sep = ""), row.names = FALSE)

# Compute sample statistics for the results
df_sample_stats <- df_all_results %>%
  group_by(generator_index, generator_sample_index) %>%
  summarise_at(vars(bic_diff, bic_a0, bic_a1, mse_diff, mse_a0, mse_a1, mse_diff_uniform_x, mse_a0_uniform_x, mse_a1_uniform_x, nknots_a0, nknots_a1, nknots_diff, n), list(mean = mean, median = median, sd = sd))

# Save the result sample statistics
file_name <- paste("experiment-results-sample-stats-", experiment_finished_time, sep = "")
file_name <- gsub("[ :]", "-", file_name)
saveRDS(df_sample_stats, file = paste(file_name, ".Rds", sep = ""))
write.csv(df_sample_stats, paste(file_name, ".csv", sep = ""), row.names = FALSE)
```

Estimation of population mean differences for BIC scores for A0 and A1 models

```{r}
library(boot)

compute_mean_ci <- function(d) {
  # Compute 95% CI for the mean difference in BIC for A0 and A1.
  # If the BIC scores are normally distributed, then do a two-sided paired t-test,
  # otherwise use bootstrapping.
  if (shapiro.test(d$bic_a0)$p.value >= 0.05 && shapiro.test(d$bic_a1)$p.value >= 0.05) {
    t_res <- t.test(d$bic_a0, d$bic_a1, paired = TRUE, alternative = "two.sided")
    mean_ci <- list(test.type = "t-test", conf.int = t_res$conf.int, p.value = t_res$p.value)
  } else {
    b1 <- boot(d$bic_diff, function(u, i) mean(u[i]), R = 1000)
    b_res <- boot.ci(b1, type = c("norm"))
    mean_ci <- list(test.type = "bootstrap", conf.int = c(b_res$normal[2], b_res$normal[3]), R.value = b_res$R)
  }
  
  return(mean_ci)
}
```

Bar-chart with pairwise better, equal, worse BICs for A0 and A1 models

```{r}
library(ggplot2)
library(scales)

plot_bic_difference_categories <- function(d, mean_ci, curve_name, m, n) {
  d$bic_diff_cats <- cut(d$bic_diff, c(-Inf, -0.5, 0.5, Inf), c("Worse (W)", "Equally good (E)", "Better (B)"), right = FALSE) 

  title <- paste("'", curve_name,  " Curve Regression Results Categorized by'~BIC[A[0]] - BIC[A[1]]", sep = "")

  if (mean_ci$test.type == "t-test") {
    p_str <- paste("p = ", signif(mean_ci$p.value, digits = 3), sep = "")
  } else {
    p_str <- paste("R = ", signif(mean_ci$R.value, digits = 3), sep = "")
  }
 
  ci_str <- paste("95% CI[", signif(mean_ci$conf.int[1], digits = 3), ", ", signif(mean_ci$conf.int[2], digits = 3), "]", sep = "")
  
  m_n_str <- paste(m, " samples of n = ", n, sep = "")
  
  subtitle <- paste("'", m_n_str, ", ",  mean_ci$test.type, "'~mu~'", ci_str, ", ", p_str, "'", sep = "")

  fig <- ggplot(d, aes(x = bic_diff_cats)) + 
    theme_bw() +
    geom_bar() +
    ggtitle(parse_format()(title), parse_format()(subtitle)) +
    xlab(parse_format()("'Differences' <= abs(0.5)~'are considered equally good.'")) + 
    ylab("Count")  
  
  return(fig)
}

```

Correlations between BICs and MSEs

```{r}
plot_bic_mse_correlations <- function(d, curve_name, m, n) {
  m_n_str <- paste(m, " samples of n = ", n, sep = "")
  subtitle <- paste("'", m_n_str, 
                    ". Avg. knots: '~A[0]~'(M=", 
                    signif(mean(d$nknots_a0), digits = 3), 
                    ", SD=", signif(sd(d$nknots_a0), digits = 3),
                    "),'~A[1]~'(M=", 
                    signif(mean(d$nknots_a1), digits = 3), 
                    ", SD=", signif(sd(d$nknots_a1), digits = 3),
                    ")'", sep = "")

    # Correlations between the pair-wise differences in BIC and MSE for the samples
  pearson_r <- cor(d$bic_diff, d$mse_diff)
  
  title <- paste("'Relationship Between BIC and'~MSE[1]~'Differences (r = ", round(pearson_r, 2), ")'", sep = "")

  fig_cor_sample <- ggplot(d, aes(x = bic_diff, y = mse_diff)) + 
    theme_bw() +
    geom_point(shape = 1, color = "gray40") +
    stat_smooth(method = "lm", color = "black", linewidth = 0.5) +
    ggtitle(
      parse_format()(title),
      parse_format()(subtitle)) +
    ylab(parse_format()("MSE[A[0]] - MSE[A[1]]")) + 
    xlab(parse_format()("BIC[A[0]] - BIC[A[1]]"))
      
  # Correlations between the pair-wise differences in BIC and MSE for uniformly distances
  # independent variable values
  pearson_r <- cor(d$bic_diff, d$mse_diff_uniform_x)

  title <- paste("'Relationship Between BIC and'~MSE[2]~'Differences (r = ", round(pearson_r, 2), ")'", sep = "")

  fig_cor_uniform_x <- ggplot(d, aes(x = bic_diff, y = mse_diff_uniform_x)) + 
    theme_bw() +
    geom_point(shape = 1, color = "gray40") +
    stat_smooth(method = "lm", color = "black", linewidth = 0.5) +
    ggtitle(
      parse_format()(title),
      parse_format()(subtitle)) +
    ylab(parse_format()("MSE[A[0]] - MSE[A[1]]")) + 
    xlab(parse_format()("BIC[A[0]] - BIC[A[1]]"))  
      
  return(list(sample = fig_cor_sample, uniform_x = fig_cor_uniform_x))
}
```

Process results grouped by generator and sample size

```{r}
library(purrr)

num_generators <- length(generators)
num_sample_sizes <- length(sample_sizes)

process_result_group <- function(generator_and_size_index) {
  generator_index <- generator_and_size_index[[1]]
  sample_size_index <- generator_and_size_index[[2]]
  
  curve_name <- generators[[generator_index]]
  m <- samples_per_set
  n <- sample_sizes[[generator_index]]
  
  d <- df_all_results[df_all_results$generator_index == generator_index & df_all_results$generator_sample_index == sample_size_index, ]
  
  # Compute confidence intervals for the mean pairwise difference in BIC scores for A0 and A1 models
  mean_ci <- compute_mean_ci(d)
  
  # Plot bar-chart with categories better, equal, worse BIC scores for A1 compared to A0
  fig <- plot_bic_difference_categories(d, mean_ci, curve_name, m, n)
  plot(fig)
  
  figs <- plot_bic_mse_correlations(d, curve_name, m, n)
  plot(figs$sample)
  plot(figs$uniform_x)

  # Save plots
  file_name_pattern <- paste("fig-", curve_name, "-%s-seed-", seed, "-", experiment_finished_time, ".png", sep = "")
  file_name <- gsub("[ :]", "-", file_name)
  file_name <- tolower(file_name)
  ggsave(sprintf(file_name, "bic-diff-cats"), plot = fig, device = "png", dpi = "print")
  ggsave(sprintf(file_name, "bic-vs-mse1-diffs"), plot = figs$sample, device = "png", dpi = "print")
  ggsave(sprintf(file_name, "bic-vs-mse2-diffs"), plot = figs$uniform_x, device = "png", dpi = "print")
}

generator_and_size_indices <- expand.grid(1:num_generators, 1:num_sample_sizes, KEEP.OUT.ATTRS = TRUE) %>% purrr::transpose()

res <- lapply(generator_and_size_indices, process_result_group)
```
